{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bank Costumer satisfaction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96XhAXeoi3fQ",
        "colab_type": "text"
      },
      "source": [
        "bank customer satisfaction using CNN and feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcqnHTBmjCtB",
        "colab_type": "code",
        "outputId": "bb70d7d6-cd70-4be1-baa7-e0bb2fe25826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.9MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0) (42.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvpvV8OrjbjG",
        "colab_type": "code",
        "outputId": "1bead0d2-7b3a-4cce-a6bb-afa0a97a7c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "print(tf.__version__) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ZNa_c1jkEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVbw5IYukNr7",
        "colab_type": "code",
        "outputId": "91bed3ba-22e8-4c89-ef1e-2a6c0c4a50a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/laxmimerit/Data-Files-for-Feature-Selection.git\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Data-Files-for-Feature-Selection'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/17)\u001b[K\rremote: Counting objects:  11% (2/17)\u001b[K\rremote: Counting objects:  17% (3/17)\u001b[K\rremote: Counting objects:  23% (4/17)\u001b[K\rremote: Counting objects:  29% (5/17)\u001b[K\rremote: Counting objects:  35% (6/17)\u001b[K\rremote: Counting objects:  41% (7/17)\u001b[K\rremote: Counting objects:  47% (8/17)\u001b[K\rremote: Counting objects:  52% (9/17)\u001b[K\rremote: Counting objects:  58% (10/17)\u001b[K\rremote: Counting objects:  64% (11/17)\u001b[K\rremote: Counting objects:  70% (12/17)\u001b[K\rremote: Counting objects:  76% (13/17)\u001b[K\rremote: Counting objects:  82% (14/17)\u001b[K\rremote: Counting objects:  88% (15/17)\u001b[K\rremote: Counting objects:  94% (16/17)\u001b[K\rremote: Counting objects: 100% (17/17)\u001b[K\rremote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOL5Lkhynri2",
        "colab_type": "code",
        "outputId": "f8d597bd-1bb9-4933-8a1e-6e261f004e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "data = pd.read_csv('/content/Data-Files-for-Feature-Selection/santander-train.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>imp_op_var40_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult3</th>\n",
              "      <th>imp_op_var41_efect_ult1</th>\n",
              "      <th>imp_op_var41_efect_ult3</th>\n",
              "      <th>imp_op_var41_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult3</th>\n",
              "      <th>imp_op_var39_ult1</th>\n",
              "      <th>imp_sal_var16_ult1</th>\n",
              "      <th>ind_var1_0</th>\n",
              "      <th>ind_var1</th>\n",
              "      <th>ind_var2_0</th>\n",
              "      <th>ind_var2</th>\n",
              "      <th>ind_var5_0</th>\n",
              "      <th>ind_var5</th>\n",
              "      <th>ind_var6_0</th>\n",
              "      <th>ind_var6</th>\n",
              "      <th>ind_var8_0</th>\n",
              "      <th>ind_var8</th>\n",
              "      <th>ind_var12_0</th>\n",
              "      <th>ind_var12</th>\n",
              "      <th>ind_var13_0</th>\n",
              "      <th>ind_var13_corto_0</th>\n",
              "      <th>ind_var13_corto</th>\n",
              "      <th>ind_var13_largo_0</th>\n",
              "      <th>ind_var13_largo</th>\n",
              "      <th>ind_var13_medio_0</th>\n",
              "      <th>ind_var13_medio</th>\n",
              "      <th>ind_var13</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var5_ult1</th>\n",
              "      <th>saldo_medio_var5_ult3</th>\n",
              "      <th>saldo_medio_var8_hace2</th>\n",
              "      <th>saldo_medio_var8_hace3</th>\n",
              "      <th>saldo_medio_var8_ult1</th>\n",
              "      <th>saldo_medio_var8_ult3</th>\n",
              "      <th>saldo_medio_var12_hace2</th>\n",
              "      <th>saldo_medio_var12_hace3</th>\n",
              "      <th>saldo_medio_var12_ult1</th>\n",
              "      <th>saldo_medio_var12_ult3</th>\n",
              "      <th>saldo_medio_var13_corto_hace2</th>\n",
              "      <th>saldo_medio_var13_corto_hace3</th>\n",
              "      <th>saldo_medio_var13_corto_ult1</th>\n",
              "      <th>saldo_medio_var13_corto_ult3</th>\n",
              "      <th>saldo_medio_var13_largo_hace2</th>\n",
              "      <th>saldo_medio_var13_largo_hace3</th>\n",
              "      <th>saldo_medio_var13_largo_ult1</th>\n",
              "      <th>saldo_medio_var13_largo_ult3</th>\n",
              "      <th>saldo_medio_var13_medio_hace2</th>\n",
              "      <th>saldo_medio_var13_medio_hace3</th>\n",
              "      <th>saldo_medio_var13_medio_ult1</th>\n",
              "      <th>saldo_medio_var13_medio_ult3</th>\n",
              "      <th>saldo_medio_var17_hace2</th>\n",
              "      <th>saldo_medio_var17_hace3</th>\n",
              "      <th>saldo_medio_var17_ult1</th>\n",
              "      <th>saldo_medio_var17_ult3</th>\n",
              "      <th>saldo_medio_var29_hace2</th>\n",
              "      <th>saldo_medio_var29_hace3</th>\n",
              "      <th>saldo_medio_var29_ult1</th>\n",
              "      <th>saldo_medio_var29_ult3</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.170000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>300.0</td>\n",
              "      <td>122.22</td>\n",
              "      <td>300.0</td>\n",
              "      <td>240.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.030000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.770000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>91.56</td>\n",
              "      <td>138.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64007.970000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>40501.08</td>\n",
              "      <td>13501.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85501.89</td>\n",
              "      <td>85501.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 371 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  var3  var15  ...  saldo_medio_var44_ult3          var38  TARGET\n",
              "0   1     2     23  ...                     0.0   39205.170000       0\n",
              "1   3     2     34  ...                     0.0   49278.030000       0\n",
              "2   4     2     23  ...                     0.0   67333.770000       0\n",
              "3   8     2     37  ...                     0.0   64007.970000       0\n",
              "4  10     2     39  ...                     0.0  117310.979016       0\n",
              "\n",
              "[5 rows x 371 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61-hByVsoO1e",
        "colab_type": "code",
        "outputId": "4f663b79-6ce2-475f-8f1f-da8740223b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76020, 371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fB7-eLvoX3Z",
        "colab_type": "code",
        "outputId": "a000211a-7ab0-4f10-b3a3-7fbada9623df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.drop(labels =['ID','TARGET'], axis = 1)\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76020, 369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9145zFuPoX6u",
        "colab_type": "code",
        "outputId": "73e45423-b0d8-445d-f28d-245b8f36df42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = data['TARGET']\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76020,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_d6o8jYoX-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,stratify = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjTrUImYpQZ6",
        "colab_type": "code",
        "outputId": "e939c794-90e6-4075-f405-58cffec9f6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60816, 369), (15204, 369))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW4X2O-Zpctf",
        "colab_type": "text"
      },
      "source": [
        "remove constants, quashi constants and duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj7OmBhUpijb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter = VarianceThreshold(0.01) # if any col has variance less than 1% then it will be dropped\n",
        "x_train = filter.fit_transform(x_train)\n",
        "x_test = filter.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmItvKjHqWLI",
        "colab_type": "code",
        "outputId": "e2c37806-7652-4214-a814-7e96305ebc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60816, 267), (15204, 267))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tyfYMN0qmst",
        "colab_type": "text"
      },
      "source": [
        "here we can see 369-267 = 102 features are dropped or filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoCL0i53q96L",
        "colab_type": "text"
      },
      "source": [
        "Now its time to remove duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFTNvB34rK3r",
        "colab_type": "text"
      },
      "source": [
        "for removing duplicates we will convert rows into columns(by doing transpose) and drop those with duplicate value and again transpose the result to get the actual format.\n",
        "Twice transpose to get original design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-arFhgiqwSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_T = x_train.T\n",
        "x_test_T = x_test.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5rWGxtFrucI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_T = pd.DataFrame(x_train_T)\n",
        "x_test_T = pd.DataFrame(x_test_T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFjPaWqosC1r",
        "colab_type": "code",
        "outputId": "a00c8e39-52cf-4b2b-96d6-1b59266e55f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_T.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(267, 60816)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlARThjfscmy",
        "colab_type": "code",
        "outputId": "8bb61138-6bbd-4a42-8217-b9b1c46aa84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_T.duplicated().sum()  # gives how many features are duplicated"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj6A06UNsi3c",
        "colab_type": "code",
        "outputId": "9d1bd1a8-9ed6-4a19-f208-b02429a3eccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "duplicated_features = x_train_T.duplicated()  \n",
        "duplicated_features  # if True then duplicated else not duplicated"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "262    False\n",
              "263    False\n",
              "264    False\n",
              "265    False\n",
              "266    False\n",
              "Length: 267, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUHpaPbWtLWW",
        "colab_type": "code",
        "outputId": "bd41ca37-fd0e-41f6-f9d7-bc476fd679ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "features_to_keep = [not index for index in duplicated_features]\n",
        "features_to_keep  # this inverts the value means False if duplicated and True if not"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jogHwxxoty3N",
        "colab_type": "code",
        "outputId": "2441981e-7190-4b89-c018-2bc4ed0b3ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# AGAIN TRANSPOSE\n",
        "x_train = x_train_T[features_to_keep]\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251, 60816)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i_U8TG6uZN6",
        "colab_type": "text"
      },
      "source": [
        "from 267 to 251, means the duplicated are dropped.\n",
        "Why did we convert True to False and vice versa?                 ans=> The reason is that  x_train = x_train_T[features_to_keep]\n",
        "this code assigns only the true value from features_to_keep to x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fpxpQGevTIC",
        "colab_type": "text"
      },
      "source": [
        "now transpose it again\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XeSwUzMuSG_",
        "colab_type": "code",
        "outputId": "4480dbf4-428b-4dc7-9b45-6d8d65498f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.T\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60816, 251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx06-PB1v2hg",
        "colab_type": "text"
      },
      "source": [
        "doing the same for testing data.\n",
        "This can also be done using function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMVzei47vfcH",
        "colab_type": "code",
        "outputId": "aa2662fc-df0c-4a65-a29d-83dbd602359f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test_T.duplicated().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3cO9Q_Tw4IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated_features_test = x_test_T.duplicated()  \n",
        "features_to_keep_test = [not index for index in duplicated_features_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Pyd0XIw4FU",
        "colab_type": "code",
        "outputId": "55732222-199e-4237-b9cc-9fd31343e557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test = x_test_T[features_to_keep]\n",
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251, 15204)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMZyk2hjx3Q_",
        "colab_type": "code",
        "outputId": "72d3f880-c8df-47e3-b8a6-2fd7cfc15594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test = x_test.T\n",
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15204, 251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq3kXdHqxV5I",
        "colab_type": "text"
      },
      "source": [
        "I did the same for x_test what I did previously for x_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKByyE_QyXLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2no6grK0yXVv",
        "colab_type": "code",
        "outputId": "adb52b08-1cad-4a94-9feb-147a6778f6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>39</th>\n",
              "      <th>41</th>\n",
              "      <th>...</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.42</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171199.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.35</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20828.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.4</td>\n",
              "      <td>95.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.4</td>\n",
              "      <td>95.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11976.6</td>\n",
              "      <td>4373.70</td>\n",
              "      <td>13539.0</td>\n",
              "      <td>9963.09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>121172.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117310.979016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118181.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 251 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1    2     3     4    5    ...  261  262  263  264  265            266\n",
              "0  2.0  25.0  0.0   0.0   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  171199.230000\n",
              "1  2.0  23.0  0.0   0.0   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   20828.070000\n",
              "2  2.0  54.0  0.0  95.4  95.4  0.0  ...  0.0  0.0  0.0  0.0  0.0  121172.010000\n",
              "3  2.0  23.0  0.0   0.0   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  117310.979016\n",
              "4  2.0  25.0  0.0   0.0   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  118181.040000\n",
              "\n",
              "[5 rows x 251 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccc_h2Ncwecn",
        "colab_type": "text"
      },
      "source": [
        "there are a lot of variances in our dataset so we need to use StandardScalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MigTpSryymiG",
        "colab_type": "code",
        "outputId": "a672cc28-4ee8-4a38-922b-c9e4687b3447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03890445, -0.63451614, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 ,  0.30135829],\n",
              "       [ 0.03890445, -0.78884607, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 , -0.5361839 ],\n",
              "       [ 0.03890445,  1.60326788, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 ,  0.02271505],\n",
              "       ...,\n",
              "       [ 0.03890445, -0.40302124, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 , -0.34584568],\n",
              "       [ 0.03890445, -0.17152634, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 , -0.03735092],\n",
              "       [ 0.03890445,  2.99223727, -0.05352825, ..., -0.01832219,\n",
              "        -0.0204875 , -0.1370209 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2JjFgDiymqj",
        "colab_type": "code",
        "outputId": "3d38fdb7-c234-42da-e8c7-b523bf4785b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60816, 251), (15204, 251))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idq5ygamweu1",
        "colab_type": "text"
      },
      "source": [
        "reshape into 3 dimension so that it can be passed to neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_crCzBfwK2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60816,251,1)\n",
        "x_test = x_test.reshape(15204,251,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnL6x8OtzkvZ",
        "colab_type": "code",
        "outputId": "2dfa2e6e-cd70-4955-d330-32fff00c9e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60816,), (15204,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVJJlPxQzuIL",
        "colab_type": "text"
      },
      "source": [
        "converting Y terms to numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzizBlOPzptb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa33Wr-_z7oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe_LfwyZz-7y",
        "colab_type": "text"
      },
      "source": [
        "*** Now lets build a Neural Network ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBQ9rlf0Eyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(32,kernel_size=3,activation='relu', input_shape = (251,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(64,kernel_size=3,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv1D(128,kernel_size=3,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUuaMJeS1Wqk",
        "colab_type": "text"
      },
      "source": [
        "1. first we made a input Convolution layer of 32 nodes and (251,1) input size.\n",
        "2. Then we added another Convolution layer of 64 nodes. Its a inside layer(hidden) so we dont need to specify input size as it recieves input from the prev layer.\n",
        "3. added another Convulation layer of 128 nodes. Last layer of Convolution.\n",
        "4. added a flatten layer which flattens the prev output into 1 dimension\n",
        "5.added a Dense layer(fully connected layers of 256 nodes). It is the begining layer of Neural network\n",
        "6. Now there is only the last layer with one neuron which determines either the costumer is satisfied or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA3mzXy-3Bug",
        "colab_type": "code",
        "outputId": "bdd2e742-eebc-4db7-e392-bd2810642536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 249, 32)           128       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 249, 32)           128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 122, 64)           6208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 122, 64)           256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 61, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 61, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 59, 128)           24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 59, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 29, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 29, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3712)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               950528    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 982,721\n",
            "Trainable params: 982,273\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vESOiO2c33Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(lr = 0.00005), loss='binary_crossentropy', metrics=['accuracy']) \n",
        "# binary cross entropy because its a binary classification problem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxy4YRY3ibL",
        "colab_type": "code",
        "outputId": "53c3ebe9-7623-43d2-9d44-5dd78a0b6cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60816 samples, validate on 15204 samples\n",
            "Epoch 1/10\n",
            "60816/60816 [==============================] - 112s 2ms/sample - loss: 0.2274 - accuracy: 0.9515 - val_loss: 0.1785 - val_accuracy: 0.9603\n",
            "Epoch 2/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1793 - accuracy: 0.9594 - val_loss: 0.1726 - val_accuracy: 0.9597\n",
            "Epoch 3/10\n",
            "60816/60816 [==============================] - 108s 2ms/sample - loss: 0.1691 - accuracy: 0.9601 - val_loss: 0.1676 - val_accuracy: 0.9603\n",
            "Epoch 4/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1667 - accuracy: 0.9603 - val_loss: 0.1633 - val_accuracy: 0.9603\n",
            "Epoch 5/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1626 - accuracy: 0.9604 - val_loss: 0.1611 - val_accuracy: 0.9603\n",
            "Epoch 6/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1604 - accuracy: 0.9604 - val_loss: 0.1558 - val_accuracy: 0.9604\n",
            "Epoch 7/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1580 - accuracy: 0.9604 - val_loss: 0.1506 - val_accuracy: 0.9603\n",
            "Epoch 8/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1572 - accuracy: 0.9604 - val_loss: 0.1514 - val_accuracy: 0.9604\n",
            "Epoch 9/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1563 - accuracy: 0.9604 - val_loss: 0.1522 - val_accuracy: 0.9603\n",
            "Epoch 10/10\n",
            "60816/60816 [==============================] - 109s 2ms/sample - loss: 0.1535 - accuracy: 0.9604 - val_loss: 0.1485 - val_accuracy: 0.9605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC_nmf4443YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRmEXc35EA2",
        "colab_type": "code",
        "outputId": "059e2c91-8a6c-4652-e274-f36b87e0287d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.951493,\n",
              "  0.9593857,\n",
              "  0.9601421,\n",
              "  0.9603229,\n",
              "  0.9603887,\n",
              "  0.9604052,\n",
              "  0.9604216,\n",
              "  0.9604052,\n",
              "  0.9604216,\n",
              "  0.960438],\n",
              " 'loss': [0.22739825983769688,\n",
              "  0.1792864538876203,\n",
              "  0.16908575469660808,\n",
              "  0.16668373066613437,\n",
              "  0.1625799409686437,\n",
              "  0.16040660934882928,\n",
              "  0.15804454515193425,\n",
              "  0.15722501061619568,\n",
              "  0.15631969093147374,\n",
              "  0.15350613399695187],\n",
              " 'val_accuracy': [0.96033937,\n",
              "  0.95974743,\n",
              "  0.96033937,\n",
              "  0.9602736,\n",
              "  0.96033937,\n",
              "  0.9604052,\n",
              "  0.96033937,\n",
              "  0.9604052,\n",
              "  0.9602736,\n",
              "  0.9604709],\n",
              " 'val_loss': [0.17851332499175457,\n",
              "  0.17259313811329252,\n",
              "  0.16764278729931129,\n",
              "  0.16334950707664664,\n",
              "  0.1610658646700132,\n",
              "  0.15584389188211,\n",
              "  0.15059555774386527,\n",
              "  0.15140599659914813,\n",
              "  0.15216955231192456,\n",
              "  0.14849909809603012]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpAu0i-75EPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_curve(history):\n",
        "  epoch_range =range(1,11)\n",
        "  plt.plot(epoch_range, history.history['accuracy'])\n",
        "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "  plt.title(\"Model_Accuracy\")\n",
        "  \n",
        "  plt.ylabel(\"accuracy\")\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.legend(['train','val'], loc = \"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epoch_range, history.history['loss'])\n",
        "  plt.plot(epoch_range, history.history['val_loss'])\n",
        "  plt.title(\"Model_loss\")\n",
        "  \n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.legend(['train','val'], loc = \"upper right\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWK_PkTh9GEf",
        "colab_type": "code",
        "outputId": "5603ef1d-2602-40a7-81f2-a39e7804e378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plot_curve(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgWHiIiU5P8DIygy1CzrFEEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMSak/x/A1Qg+ybyNfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr3NnBlGqMTF",
        "colab_type": "text"
      },
      "source": [
        "from the above graph its clear that model started overfitting after 8th epoch as yellow line came below the blue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqF-dP1Tqdq2",
        "colab_type": "text"
      },
      "source": [
        "now doing our prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91fDin7Eg5MT",
        "colab_type": "code",
        "outputId": "b6159226-476d-440c-9320-65641a048cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = x_test[1]\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyQn46b6kmky",
        "colab_type": "code",
        "outputId": "53eeb6ae-7e65-442d-904a-4848a6e0fa99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.reshape(a,(1,251,1))\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 251, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKdkrL1rVce",
        "colab_type": "text"
      },
      "source": [
        "yasari chai 2d numpy array 3d hunxa hai gaich"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zepvCU92jU30",
        "colab_type": "code",
        "outputId": "250881e8-691c-4cbc-9514-a85864867a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pr = model.predict(a)\n",
        "print(pr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0048339]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Oz9T9SkePo",
        "colab_type": "code",
        "outputId": "d3abaa4b-2c60-47e8-daef-74c07b32e962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prc = model.predict_classes(a)\n",
        "print(\"actual:-\" +str(y_test[0])+ \"  predicted:-\" + str(prc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual:-0  predicted:-[[0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU9samNysW99",
        "colab_type": "text"
      },
      "source": [
        "this is how a neural network is used for checking bank customer satisfaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4NvdH5-sfyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}